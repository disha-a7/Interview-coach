{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "94ae9f724d8e4918adae8f91314a5ab9",
            "7c1fb4687d72478bb2dbcebf72b226e9",
            "c5251115816a4c78865d55fd522abbe5",
            "8de07df44dbe4a41933d6c7421aa1623",
            "3a2e841c50fb4c0e900cb8e362fc9ffd",
            "b47487974cc341b78acb64cb53f79831",
            "08b0b4d5cfe24e72a13934a267ba2510",
            "b9200300f3ad4d1ebd07ac2736a16b5c",
            "6272786fa00245d2a5635c00841b861c",
            "bdf57ff6fce44bdb8a7a8f11be4cd6c5",
            "e12610f35757447587e022075a2034c4",
            "f7cf8550b9f34a8ab99b8524cd8cf3ee",
            "43abf46204424088923983049600d5a9",
            "bd1f55b1d00b42acb1fb65fca09f90fe",
            "613089a63e5847458b5271bd91558735",
            "403609af38fd4a2386c966175feef031",
            "577f1dc7435b43f6b1119528adc991e3"
          ]
        },
        "id": "kYuCfFmPHR1W",
        "outputId": "6a364d1a-1b6d-4028-9c96-6157badc9435"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94ae9f724d8e4918adae8f91314a5ab9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c1fb4687d72478bb2dbcebf72b226e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5251115816a4c78865d55fd522abbe5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8de07df44dbe4a41933d6c7421aa1623",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a2e841c50fb4c0e900cb8e362fc9ffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b47487974cc341b78acb64cb53f79831",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08b0b4d5cfe24e72a13934a267ba2510",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9200300f3ad4d1ebd07ac2736a16b5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6272786fa00245d2a5635c00841b861c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdf57ff6fce44bdb8a7a8f11be4cd6c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e12610f35757447587e022075a2034c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7cf8550b9f34a8ab99b8524cd8cf3ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43abf46204424088923983049600d5a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd1f55b1d00b42acb1fb65fca09f90fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "613089a63e5847458b5271bd91558735",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "403609af38fd4a2386c966175feef031",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "577f1dc7435b43f6b1119528adc991e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a75a59f4423a2f13e7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a75a59f4423a2f13e7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "questions = {\"HR\": \"Tell me about yourself.\",\n",
        "             \"Tech\": \"Explain a project you worked on .\",\n",
        "             \"Product\": \"How would you improve our app ?\"}\n",
        "\n",
        "summarizer = pipeline(\"summarization\" , model = \"t5-small\")\n",
        "evaluator = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def interview_coach(domain, user_answer):\n",
        "    question = questions[domain]\n",
        "    summary = summarizer(user_answer, max_length = 40, min_length = 20 , do_sample= False)[0]['summary_text']\n",
        "    q_embed = evaluator.encode(question,convert_to_tensor = True)\n",
        "    a_embed = evaluator.encode(user_answer, convert_to_tensor = True)\n",
        "    similarity = util.pytorch_cos_im(q_embed,a_embed).item()\n",
        "    feedback = f\"Feedback:{summary} \\n\\n Relevance score:{round(similarity*100,2)}%\"\n",
        "    return feedback\n",
        "\n",
        "\n",
        "gr.Interface(\n",
        "     fn=interview_coach,\n",
        "     inputs = [\n",
        "         gr.Dropdown(choices = list(questions.keys()), label = \"Select Interview Domain\"),\n",
        "         gr.Textbox(lines=5, placeholder = \"Type your answer here...\", label =\"Your Answer\"),\n",
        "         ],\n",
        "     outputs=[\n",
        "        gr.Textbox(label=\"Interview Question\"),\n",
        "        gr.Textbox(label=\"AI Feedback\")\n",
        "    ],\n",
        "     title= \"GEN AI Interview Coach\",\n",
        "     description= \"Practice interview answers with AI feedback \",\n",
        "\n",
        ").launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "o9Er6xMXJb2p",
        "outputId": "bc9a652e-0219-47ab-d3b0-fb1cb0b08167"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://88ce5273f1673164eb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://88ce5273f1673164eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "questions = {\n",
        "    \"HR\": \"Tell me about yourself.\",\n",
        "    \"Tech\": \"Explain a project you worked on.\",\n",
        "    \"Product\": \"How would you improve our app?\"\n",
        "}\n",
        "\n",
        "# Load models\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
        "evaluator = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function to show question only\n",
        "def get_question(domain):\n",
        "    return questions[domain]\n",
        "\n",
        "# Function to analyze answer\n",
        "def interview_feedback(domain, user_answer):\n",
        "    question = questions[domain]\n",
        "    summary = summarizer(user_answer, max_length=40, min_length=20, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    q_embed = evaluator.encode(question, convert_to_tensor=True)\n",
        "    a_embed = evaluator.encode(user_answer, convert_to_tensor=True)\n",
        "    similarity = util.pytorch_cos_sim(q_embed, a_embed).item()\n",
        "\n",
        "    feedback = f\"Summary: {summary}\\n\\nüìä Relevance Score: {round(similarity * 100, 2)}%\"\n",
        "    return feedback\n",
        "\n",
        "# UI Blocks style for multi-step logic\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üéØ GEN AI Interview Coach\")\n",
        "    gr.Markdown(\"Practice interview answers with AI feedback\")\n",
        "\n",
        "    with gr.Row():\n",
        "        domain = gr.Dropdown(choices=list(questions.keys()), label=\"Select Interview Domain\")\n",
        "        question_output = gr.Textbox(label=\"Interview Question\", interactive=False)\n",
        "\n",
        "    get_q_btn = gr.Button(\"Show Question\")\n",
        "    get_q_btn.click(fn=get_question, inputs=domain, outputs=question_output)\n",
        "\n",
        "    answer = gr.Textbox(label=\"Your Answer\", lines=5, placeholder=\"Type your answer here...\")\n",
        "    feedback_output = gr.Textbox(label=\"AI Feedback\", interactive=False)\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit\")\n",
        "    submit_btn.click(fn=interview_feedback, inputs=[domain, answer], outputs=feedback_output)\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "3TuhlbUHJzf-",
        "outputId": "53fae084-f914-4fa9-f367-507b4604f9ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a7d72b5941a95a2430.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a7d72b5941a95a2430.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Predefined domain-based questions\n",
        "questions = {\n",
        "    \"HR\": \"Tell me about yourself.\",\n",
        "    \"Tech\": \"Explain a project you worked on.\",\n",
        "    \"Product\": \"How would you improve our app?\"\n",
        "}\n",
        "\n",
        "# Load models\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
        "evaluator = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function to return question based on selected domain\n",
        "def get_question(domain):\n",
        "    return questions[domain]\n",
        "\n",
        "# Function to return feedback\n",
        "def interview_feedback(domain, user_answer):\n",
        "    question = questions[domain]\n",
        "    summary = summarizer(user_answer, max_length=40, min_length=20, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    q_embed = evaluator.encode(question, convert_to_tensor=True)\n",
        "    a_embed = evaluator.encode(user_answer, convert_to_tensor=True)\n",
        "    similarity = util.pytorch_cos_sim(q_embed, a_embed).item()\n",
        "\n",
        "    feedback = f\"‚úçÔ∏è Summary: {summary}\\n\\nüìä Relevance Score: {round(similarity * 100, 2)}%\"\n",
        "    return feedback\n",
        "\n",
        "# Build Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üéØ GEN AI Interview Coach\")\n",
        "    gr.Markdown(\"Practice interview answers with AI feedback\")\n",
        "\n",
        "    with gr.Row():\n",
        "        domain = gr.Dropdown(choices=list(questions.keys()), label=\"Select Interview Domain\")\n",
        "        question_output = gr.Textbox(label=\"Interview Question\", interactive=False)\n",
        "\n",
        "    # Auto-update question when domain changes\n",
        "    domain.change(fn=get_question, inputs=domain, outputs=question_output)\n",
        "\n",
        "    answer = gr.Textbox(label=\"Your Answer\", lines=5, placeholder=\"Type your answer here...\")\n",
        "    feedback_output = gr.Textbox(label=\"AI Feedback\", interactive=False)\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit\")\n",
        "    submit_btn.click(fn=interview_feedback, inputs=[domain, answer], outputs=feedback_output)\n",
        "\n",
        "# Launch app\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}